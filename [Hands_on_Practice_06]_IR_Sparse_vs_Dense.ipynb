{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonseok0802/my-first-repo/blob/main/%5BHands_on_Practice_06%5D_IR_Sparse_vs_Dense.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## << 문제 정의 >>\n",
        "\n",
        "- **Retrieval(검색)** 은 주어진 쿼리에 대해 관련된 문서를 찾아오는 태스크입니다.\n",
        "\n",
        "- 전통적인 **TF-IDF** 방식과 딥러닝 기반의 **SentenceBERT** 방식의 검색 성능을 비교합니다.\n",
        "\n",
        "- 두 방식의 차이점을 이해하고, 각각의 장단점을 파악합니다.\n",
        "\n",
        "### TF-IDF vs SentenceBERT 비교\n",
        "\n",
        "| 구분 | TF-IDF | SentenceBERT |\n",
        "|------|--------|---------------|\n",
        "| 원리 | 단어 빈도 기반 (Sparse) | 의미 기반 (Dense) |\n",
        "| 벡터 차원 | 어휘 크기 (수만 차원) | 고정 크기 (384~768) |\n",
        "| 동의어 처리 | ❌ 불가능 | ✅ 가능 |\n",
        "| 전처리 의존도 | 높음 (형태소 분석 필수) | 낮음 |\n",
        "| 계산 속도 | 빠름 | 상대적으로 느림 |\n",
        "| 메모리 사용 | Sparse로 효율적 | Dense로 더 많이 사용 |"
      ],
      "metadata": {
        "id": "TYzSexngxOzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### << 진행 순서 >>\n",
        "\n",
        "1. 환경 설정 및 데이터 준비 (Ko-StrategyQA)\n",
        "\n",
        "2. 한국어 전처리 (Kiwi 형태소 분석)\n",
        "\n",
        "3. TF-IDF 기반 Retrieval 구현 (전처리 유무 비교)\n",
        "\n",
        "4. SentenceBERT 기반 Retrieval 구현 (한국어 전용 모델)\n",
        "\n",
        "5. 동일 쿼리에 대한 검색 결과 비교\n",
        "\n",
        "6. 정량적 성능 평가 (Recall@K, MRR)\n",
        "\n",
        "7. 임베딩 공간 시각화 비교"
      ],
      "metadata": {
        "id": "a2p0Jo3-fDtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 1. 환경 설정"
      ],
      "metadata": {
        "id": "env_setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kiwipiepy sentence-transformers datasets"
      ],
      "metadata": {
        "id": "FVkaWh9bxcLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정 (시각화용)\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "import_libs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 2. 데이터 준비\n",
        "\n",
        "### Ko-StrategyQA 데이터셋\n",
        "\n",
        "- **한국어 Retrieval 벤치마크** 데이터셋 (BeIR 포맷)\n",
        "- **corpus**: 9,250개 문서 (Wikipedia 기반)\n",
        "- **queries**: 592개 쿼리\n",
        "- **qrels**: 쿼리-문서 관련성 판단 (1개 쿼리당 여러 개의 relevant docs)\n",
        "- Multi-hop QA 데이터를 Retrieval용으로 변환"
      ],
      "metadata": {
        "id": "data_prep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Ko-StrategyQA 데이터셋을 로드하고 corpus, queries, qrels 데이터를 확인하는 코드를 작성하세요.\n",
        "\n",
        "- `corpus.jsonl`: 검색 대상 문서들\n",
        "- `queries.jsonl`: 검색 쿼리들\n",
        "- `qrels/`: 쿼리-문서 관련성 레이블\n",
        "\n",
        "[HINT] HuggingFace datasets 라이브러리의 `load_dataset` 함수를 사용합니다. 데이터셋 이름은 `'mteb/Ko-StrategyQA'`입니다."
      ],
      "metadata": {
        "id": "Lu0UT7gSxSmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A1.\n"
      ],
      "metadata": {
        "id": "load_dataset"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 구조 확인\n",
        "print(\"=\" * 50)\n",
        "print(\"Corpus 예시:\")\n",
        "print(corpus_data[0])\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Query 예시:\")\n",
        "print(queries_data[0])\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Qrels 예시:\")\n",
        "print(qrels_data[0])"
      ],
      "metadata": {
        "id": "data_structure"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. 검색에 사용할 데이터 구조를 만드세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. `corpus`: doc_id → text 매핑 (딕셔너리)\n",
        "2. `corpus_list`: 문서 텍스트 리스트 (임베딩용)\n",
        "3. `doc_id_list`: doc_id 순서 유지 (리스트)\n",
        "4. `queries`: query_id → query text 매핑 (딕셔너리)\n",
        "5. `qrels`: query_id → relevant doc_ids 매핑 (딕셔너리, set으로 저장)\n",
        "\n",
        "[HINT] corpus 데이터의 각 item에는 `_id`, `title`, `text` 필드가 있습니다. title과 text를 합쳐서 문서를 구성하세요."
      ],
      "metadata": {
        "id": "q2_data_structure"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A2.\n"
      ],
      "metadata": {
        "id": "build_data_structure"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 3. 한국어 전처리 (Kiwi 형태소 분석)\n",
        "\n",
        "TF-IDF는 단어(토큰) 기반으로 동작하기 때문에, 한국어의 경우 **형태소 분석**이 매우 중요합니다.\n",
        "\n",
        "### Kiwi 형태소 분석기\n",
        "\n",
        "- **높은 정확도**: 웹 텍스트 87%, 문어 텍스트 94%\n",
        "- **빠른 속도**: C++ 기반, 멀티스레딩 지원\n",
        "- **간편한 설치**: `pip install kiwipiepy`"
      ],
      "metadata": {
        "id": "preprocessing_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. Kiwi 형태소 분석기를 사용하여 문장을 토큰화하는 함수를 구현하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. `kiwipiepy.Kiwi`를 사용합니다.\n",
        "2. 명사(NN*), 동사(VV), 형용사(VA)만 추출합니다.\n",
        "3. 불용어(stopwords)를 제거합니다.\n",
        "4. 길이가 1 이하인 토큰은 제거합니다.\n",
        "\n",
        "[HINT] `kiwi.tokenize(text)`를 사용하면 토큰 리스트를 얻을 수 있고, 각 토큰의 `.form`(형태), `.tag`(품사)를 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "q3_morpheme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A3.\n"
      ],
      "metadata": {
        "id": "morpheme_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. 전체 코퍼스에 형태소 분석을 적용하는 코드를 작성하세요.\n",
        "\n",
        "[HINT] `tqdm`을 사용하면 진행 상황을 확인할 수 있습니다. 리스트 컴프리헨션을 사용하세요."
      ],
      "metadata": {
        "id": "q4_preprocess_corpus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A4.\n"
      ],
      "metadata": {
        "id": "preprocess_corpus_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 4. TF-IDF 기반 Retrieval 구현"
      ],
      "metadata": {
        "id": "tfidf_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. TF-IDF Vectorizer를 사용하여 코퍼스를 벡터화하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. 전처리 없는 TF-IDF (`tfidf_vectorizer_raw`, `tfidf_matrix_raw`)\n",
        "2. Kiwi 형태소 분석 후 TF-IDF (`tfidf_vectorizer`, `tfidf_matrix`)\n",
        "\n",
        "[HINT] `sklearn.feature_extraction.text.TfidfVectorizer`를 사용합니다."
      ],
      "metadata": {
        "id": "q5_tfidf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A5.\n"
      ],
      "metadata": {
        "id": "tfidf_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. TF-IDF 기반 검색 함수를 구현하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. `query`: 검색할 쿼리 문자열\n",
        "2. `top_k`: 반환할 상위 문서 개수 (기본값 10)\n",
        "3. `use_preprocessing`: 전처리 적용 여부 (기본값 True)\n",
        "4. 반환값: `[(doc_id, score), ...]` 형태의 리스트\n",
        "\n",
        "[HINT] `sklearn.metrics.pairwise.cosine_similarity`를 사용하여 쿼리와 문서 간의 유사도를 계산합니다."
      ],
      "metadata": {
        "id": "q6_tfidf_search"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A6.\n"
      ],
      "metadata": {
        "id": "tfidf_search_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 5. SentenceBERT 기반 Retrieval 구현"
      ],
      "metadata": {
        "id": "sbert_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. 한국어 전용 SentenceBERT 모델을 로드하고 코퍼스를 임베딩하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. `sentence_transformers.SentenceTransformer`를 사용합니다.\n",
        "2. 한국어 전용 모델을 사용합니다.\n",
        "3. 전체 코퍼스를 임베딩합니다.\n",
        "\n",
        "[HINT] 한국어 전용 모델로 `'snunlp/KR-SBERT-V40K-klueNLI-augSTS'`를 사용할 수 있습니다. 임베딩에는 약 3-5분이 소요됩니다."
      ],
      "metadata": {
        "id": "q7_sbert"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A7.\n"
      ],
      "metadata": {
        "id": "sbert_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8. SentenceBERT 기반 검색 함수를 구현하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "1. 쿼리를 임베딩합니다.\n",
        "2. 코사인 유사도를 계산합니다.\n",
        "3. 상위 K개의 문서를 반환합니다.\n",
        "\n",
        "[HINT] `sentence_transformers.util.pytorch_cos_sim`을 사용하면 코사인 유사도를 쉽게 계산할 수 있습니다. `torch.topk`로 상위 K개를 추출합니다."
      ],
      "metadata": {
        "id": "q8_sbert_search"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A8.\n"
      ],
      "metadata": {
        "id": "sbert_search_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 6. 검색 결과 비교"
      ],
      "metadata": {
        "id": "comparison_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9. 동일한 쿼리에 대해 세 가지 방식(TF-IDF 전처리X, TF-IDF Kiwi, SentenceBERT)의 검색 결과를 비교하는 함수를 구현하세요.\n",
        "\n",
        "[HINT] 각 방식의 검색 결과에서 relevant docs에 포함된 문서는 ✓ 표시를 해주면 비교하기 좋습니다."
      ],
      "metadata": {
        "id": "q9_comparison"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A9.\n"
      ],
      "metadata": {
        "id": "comparison_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 7. 정량적 성능 평가\n",
        "\n",
        "### 평가 지표\n",
        "\n",
        "- **Recall@K**: 전체 relevant docs 중 상위 K개 안에 포함된 비율\n",
        "- **MRR**: 첫 번째 relevant doc이 등장하는 순위의 역수 평균"
      ],
      "metadata": {
        "id": "evaluation_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q10. Recall@K와 MRR을 계산하는 함수를 구현하세요.\n",
        "\n",
        "**Recall@K 공식:**\n",
        "$$Recall@K = \\frac{|\\{relevant\\_docs\\} \\cap \\{top\\_K\\_retrieved\\}|}{|\\{relevant\\_docs\\}|}$$\n",
        "\n",
        "**MRR 공식:**\n",
        "$$MRR = \\frac{1}{|Q|} \\sum_{i=1}^{|Q|} \\frac{1}{rank_i}$$\n",
        "\n",
        "[HINT] Recall@K는 상위 K개 중 relevant docs가 몇 개인지 비율로 계산합니다. MRR은 첫 번째 relevant doc의 순위 역수를 평균냅니다."
      ],
      "metadata": {
        "id": "q10_metrics"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A10.\n"
      ],
      "metadata": {
        "id": "metrics_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q11. 세 가지 방식의 성능을 평가하고 비교하세요. K값은 1, 3, 5, 10으로 설정하세요.\n",
        "\n",
        "[HINT] 각 방식별로 Recall@K와 MRR을 계산하여 DataFrame으로 정리하면 보기 좋습니다."
      ],
      "metadata": {
        "id": "q11_evaluation"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A11.\n"
      ],
      "metadata": {
        "id": "evaluation_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q12. 성능 비교 결과를 시각화하세요. Recall@K는 막대 그래프로, MRR은 별도의 막대 그래프로 표현하세요.\n",
        "\n",
        "[HINT] `matplotlib.pyplot.subplots`를 사용하여 1x2 레이아웃으로 그래프를 그릴 수 있습니다."
      ],
      "metadata": {
        "id": "q12_visualization"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A12.\n"
      ],
      "metadata": {
        "id": "viz_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Part 8. 임베딩 공간 시각화"
      ],
      "metadata": {
        "id": "embedding_viz_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q13. t-SNE를 사용하여 TF-IDF와 SentenceBERT의 임베딩 공간을 2D로 시각화하세요.\n",
        "\n",
        "[HINT] 전체 데이터를 사용하면 시간이 오래 걸리므로, 500개 정도 샘플링하여 사용합니다. `sklearn.manifold.TSNE`를 사용하세요."
      ],
      "metadata": {
        "id": "q13_tsne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A13.\n"
      ],
      "metadata": {
        "id": "tsne_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## (optional)>> [Advanced] 하이브리드 검색"
      ],
      "metadata": {
        "id": "advanced_section"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q14. TF-IDF와 SentenceBERT를 결합한 하이브리드 검색 함수를 구현하세요. 아래 설명을 참고하세요.\n",
        "\n",
        "**하이브리드 점수 공식:**\n",
        "$$score = \\alpha \\times tfidf\\_score + (1-\\alpha) \\times sbert\\_score$$\n",
        "\n",
        "1. TF-IDF 점수와 SentenceBERT 점수를 각각 계산합니다.\n",
        "2. Min-Max 정규화를 적용합니다.\n",
        "3. 가중 평균으로 최종 점수를 계산합니다.\n",
        "\n",
        "[HINT] `alpha`는 TF-IDF의 가중치로, 0이면 SentenceBERT만, 1이면 TF-IDF만 사용합니다."
      ],
      "metadata": {
        "id": "q14_hybrid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A14.\n"
      ],
      "metadata": {
        "id": "hybrid_code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q15. 최적의 alpha 값을 찾는 실험을 수행하세요. alpha를 0.0부터 1.0까지 0.1 간격으로 변화시키며 Recall@5를 측정하세요.\n",
        "\n",
        "[HINT] 각 alpha 값에 대해 하이브리드 검색의 Recall@5를 계산하고, 최적의 alpha를 찾습니다."
      ],
      "metadata": {
        "id": "q15_alpha_search"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A15.\n"
      ],
      "metadata": {
        "id": "alpha_search_code"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}